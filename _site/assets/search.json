

[
  
  
    
    
  
  
  
  {
    "title": "Categories",
    "excerpt": "Category index\n",
    "content": "\n",
    "url": "/categories/"
  },
  
  {
    "title": "Reading",
    "excerpt": "A short description of the VOiCES corpus\n",
    "content": "Stay Tuned, Coming Soon\n\nWe are in the midst of uploading all of our files onto Amazon and it is taking a while!\n",
    "url": "/downloads/"
  },
  
  {
    "title": "Description",
    "excerpt": "A short description of the VOiCES corpus\n",
    "content": "SRI International and Lab41, In-Q-Tel, are proud to release the Voices Obscured in Complex Environmental Settings (VOICES) corpus, a collaborative effort that brings speech data in acoustically challenging reverberant environments to the researcher. Clean speech was recorded in rooms of different sizes, each having distinct room acoustic profiles, with background noise played concurrently. These recordings provides audio data that better represent real-use scenarios. The intended purpose of this corpus is to promote acoustic research including, but not limited to:\n\n\n  speaker Identification, speech recognition, speaker detection\n  event and background classification, speech/non-speech\n  source separation and localization, noise reduction, general enhancement, acoustic quality metrics\n\n\nThe corpus contains the source audio, the retransmitted audio, orthographic transcriptions, and speaker labels. The ultimate goal of this corpus is to advance acoustic research by providing access to complex acoustic data. The corpus will be released as open source, Creative Commons BY 4.0, free for commercial, academic, and government use.\n\nDataset Details\n\nThis is one of the largest corpora to date that has transcriptions and simulatenously recorded real-world noise. The details:\n\n\n  Source Material: a total of 15 hours (3,903 audio files)\n  Language audio contains English read speech with male and females\n  Simulated Head Movement the loudspeaker playing the foreground speech was on a motorized rotating platform\n  Distractor Noise a large collection containing television, music, babble noise, and HVAC at various SNR\n  Multiple Rooms large, medium, and small, with various reverberation\n\n\nMore specific details can be seen at in our readme and paper in the reading section\n\n",
    "url": "/"
  },
  
  {
    "title": "Description",
    "excerpt": "Links and Contacts\n",
    "content": "Sponsoring Organizations\n\n  \n \n  \n\n\nParticipating Organizations\n\n  MIT Lincoln Laboratory\n  DeepGram\n  Carnegie Melon\n  Capio\n\n\n",
    "url": "/links/"
  },
  
  {
    "title": "Organizers",
    "excerpt": "A short description of the VOiCES corpus\n",
    "content": "Colleen Richey\n\n\nColleen Richey TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\n\nMaria Barrios\n\n\nDr. Maria Alejandra Barrios Garcia TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\n\nAaron Lawson\n\n\nAaron Lawson, Ph.D., is Assistant Director of SRI International’s Speech Technology and Research (STAR) Laboratory. His research interests include voice forensics and biometrics, language and speaker identification from speech, social media information extraction, noise robustness, and fielding systems. At SRI, Lawson is the co-PI of the SAVI team for the DARPA MediFor program and is SRI transition lead for the DARPA RATS program. He currently leads the Human Language Technology project with JHU Applied Physics Lab, Forensic Speaker Recognition projects with the Federal Bureau of Investigation and transition efforts with the Navy and Special Operations Forces. He was PI for SRI’s LinguaKey team for DARPA Active Authentication. Past projects include IARPA REYNARD and BEST,\n\nPrior to joining SRI, Lawson was a research scientist at Air Force Research Laboratory/RADC in the Audio Processing Group. Earlier, he was a natural language processing researcher at TextWise, LLC.\n\nLawson has published more than 30 papers covering speech, natural language and linguistics. His Ph.D. in applied linguistics is from Cornell University.\n\nJeff Hetherly\n\n\nDr. Jeff Hetherly TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\n\nPaul Gamble\n\n\nDr. Paul Gamble\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\n\nCory Stephenson\n\n\nDr. Cory Stephenson\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\nTEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT TEXT\n\nKarl Ni\n\n\nDr. Karl Ni is the Technical Director of Lab41, In-Q-Tel’s AI and machine learning analytics laboratory. His interests lie in computer vision, audio signal processing, speech recognition, and natural language processing. Prior to In-Q-Tel, Dr. Ni served as principle investigator and program manager on laboratory directed projects at federally funded research and development centers, both MIT Lincoln Laboratory and Lawrence Livermore National Laboratory. Projects started and led at these organizations resided under the President’s BRAIN initiative, the Departments of Defense and Homeland Security, and internally funded research. Dr. Ni received his doctoral degree from the University of California, San Diego in Pattern Recognition Techniques for Image Processing, and he received his bachelors degree from the University of California at Berkeley.\n",
    "url": "/organizers/"
  },
  
  {
    "title": "Reading",
    "excerpt": "A short description of the VOiCES corpus\n",
    "content": "Dataset Description\n\nData format\n\n\n  \n    \n      File Code\n      Type\n      Definition\n    \n  \n  \n    \n      Lab41-SRI-VOiCES\n      General info\n      Data set name: Lab41-SRI Voices Obscured in Complex Environmental Settings\n    \n    \n      rm1\n      Recording location\n      Room-1: dimensions 146” x 107” (x 107” height)\n    \n    \n      rm2\n      Recording location\n      Room-2: dimensions 225” x 158” (x 109” height)\n    \n    \n      scr\n      Source audio\n      Source audio for foreground speaker\n    \n    \n      none\n      Background noise\n      No distractor noise played\n    \n    \n      musi\n      Background noise\n      Music distractor noise played\n    \n    \n      tele\n      Background noise\n      Television distractor noise played\n    \n    \n      babb\n      Background noise\n      Babble distractor noise played\n    \n    \n      stu\n      Microphone type\n      Cardioid dynamic studio microphone\n    \n    \n      lav\n      Microphone type\n      Omnidirectional condenser lavalier microphone\n    \n    \n      clo\n      Location\n      Closest to foreground speaker- on table\n    \n    \n      mid\n      Location\n      Mid-distance to foreground speaker- on table\n    \n    \n      far\n      Location\n      Farthest to foreground speaker- on stand\n    \n    \n      beh\n      Location\n      Behind foreground speaker- on stand\n    \n    \n      cei\n      Location\n      Overhead - hanging from ceiling\n    \n    \n      ceo\n      Location\n      Overhead - hanging from ceiling / obstructed\n    \n    \n      impulse\n      Room response\n      Two seconds with transient sound in middle\n    \n    \n      swoop\n      Room response\n      Rising tone for 20 seconds\n    \n    \n      tone\n      Room response\n      Steady tone for 15 seconds\n    \n  \n\n\nBlog Posts\n\n\n  Maria’s Blog Post\n\n\nPublications\n\n\n  Interspeech (ArXiv)\n  Abstract for ASA\n  Poster for ASA ?\n  Jeff’s Paper (ArXiv)\n  Cory’s Paper\n  Any references from SRI ?\n\n\n",
    "url": "/reading/"
  },
  
  {
    "title": "Search",
    "excerpt": "Search for a page or post you’re looking for\n",
    "content": "{% include site-search.html %}\n",
    "url": "/search/"
  }
  
]

